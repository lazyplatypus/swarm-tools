/**
 * OpenCode Swarm Plugin Wrapper
 *
 * This is a thin wrapper that shells out to the `swarm` CLI for all tool execution.
 * Generated by: swarm setup
 *
 * The plugin only depends on @opencode-ai/plugin (provided by OpenCode).
 * All tool logic lives in the npm package - this just bridges to it.
 *
 * Environment variables:
 * - OPENCODE_SESSION_ID: Passed to CLI for session state persistence
 * - OPENCODE_MESSAGE_ID: Passed to CLI for context
 * - OPENCODE_AGENT: Passed to CLI for context
 * - SWARM_PROJECT_DIR: Project directory (critical for database path)
 */
import type { Plugin, PluginInput, Hooks } from "@opencode-ai/plugin";
import { tool } from "@opencode-ai/plugin";
import { spawn } from "child_process";
import { appendFileSync, mkdirSync, existsSync } from "node:fs";
import { join } from "node:path";
import { homedir } from "node:os";

const SWARM_CLI = "swarm";

// =============================================================================
// File-based Logging (writes to ~/.config/swarm-tools/logs/)
// =============================================================================

const LOG_DIR = join(homedir(), ".config", "swarm-tools", "logs");
const COMPACTION_LOG = join(LOG_DIR, "compaction.log");

/**
 * Ensure log directory exists
 */
function ensureLogDir(): void {
  if (!existsSync(LOG_DIR)) {
    mkdirSync(LOG_DIR, { recursive: true });
  }
}

/**
 * Log a compaction event to file (JSON lines format, compatible with `swarm log`)
 * 
 * @param level - Log level (info, debug, warn, error)
 * @param msg - Log message
 * @param data - Additional structured data
 */
function logCompaction(
  level: "info" | "debug" | "warn" | "error",
  msg: string,
  data?: Record<string, unknown>,
): void {
  try {
    ensureLogDir();
    const entry = JSON.stringify({
      time: new Date().toISOString(),
      level,
      msg,
      ...data,
    });
    appendFileSync(COMPACTION_LOG, entry + "\n");
  } catch {
    // Silently fail - logging should never break the plugin
  }
}

// Module-level project directory - set during plugin initialization
// This is CRITICAL: without it, the CLI uses process.cwd() which may be wrong
let projectDirectory: string = process.cwd();

// =============================================================================
// CLI Execution Helper
// =============================================================================

/**
 * Execute a swarm tool via CLI
 *
 * Spawns `swarm tool <name> --json '<args>'` and returns the result.
 * Passes session context via environment variables.
 * 
 * IMPORTANT: Runs in projectDirectory (set by OpenCode) not process.cwd()
 */
async function execTool(
  name: string,
  args: Record<string, unknown>,
  ctx: { sessionID: string; messageID: string; agent: string },
): Promise<string> {
  return new Promise((resolve, reject) => {
    const hasArgs = Object.keys(args).length > 0;
    const cliArgs = hasArgs
      ? ["tool", name, "--json", JSON.stringify(args)]
      : ["tool", name];

    const proc = spawn(SWARM_CLI, cliArgs, {
      cwd: projectDirectory, // Run in project directory, not plugin directory
      stdio: ["ignore", "pipe", "pipe"],
      env: {
        ...process.env,
        OPENCODE_SESSION_ID: ctx.sessionID,
        OPENCODE_MESSAGE_ID: ctx.messageID,
        OPENCODE_AGENT: ctx.agent,
        SWARM_PROJECT_DIR: projectDirectory, // Also pass as env var
      },
    });

    let stdout = "";
    let stderr = "";

    proc.stdout.on("data", (data) => {
      stdout += data;
    });
    proc.stderr.on("data", (data) => {
      stderr += data;
    });

    proc.on("close", (code) => {
      if (code === 0) {
        // Success - return the JSON output
        try {
          const result = JSON.parse(stdout);
          if (result.success && result.data !== undefined) {
            // Unwrap the data for cleaner tool output
            resolve(
              typeof result.data === "string"
                ? result.data
                : JSON.stringify(result.data, null, 2),
            );
          } else if (!result.success && result.error) {
            // Tool returned an error in JSON format
            // Handle both string errors and object errors with .message
            const errorMsg = typeof result.error === "string" 
              ? result.error 
              : (result.error.message || "Tool execution failed");
            reject(new Error(errorMsg));
          } else {
            resolve(stdout);
          }
        } catch {
          resolve(stdout);
        }
      } else if (code === 2) {
        reject(new Error(`Unknown tool: ${name}`));
      } else if (code === 3) {
        reject(new Error(`Invalid JSON args: ${stderr}`));
      } else {
        // Tool returned error
        try {
          const result = JSON.parse(stdout);
          if (!result.success && result.error) {
            // Handle both string errors and object errors with .message
            const errorMsg = typeof result.error === "string"
              ? result.error
              : (result.error.message || `Tool failed with code ${code}`);
            reject(new Error(errorMsg));
          } else {
            reject(
              new Error(stderr || stdout || `Tool failed with code ${code}`),
            );
          }
        } catch {
          reject(
            new Error(stderr || stdout || `Tool failed with code ${code}`),
          );
        }
      }
    });

    proc.on("error", (err) => {
      if ((err as NodeJS.ErrnoException).code === "ENOENT") {
        reject(
          new Error(
            `swarm CLI not found. Install with: npm install -g opencode-swarm-plugin`,
          ),
        );
      } else {
        reject(err);
      }
    });
  });
}

// =============================================================================
// Beads Tools
// =============================================================================

const hive_create = tool({
  description: "Create a new bead with type-safe validation",
  args: {
    title: tool.schema.string().describe("Bead title"),
    type: tool.schema
      .enum(["bug", "feature", "task", "epic", "chore"])
      .optional()
      .describe("Issue type (default: task)"),
    priority: tool.schema
      .number()
      .min(0)
      .max(3)
      .optional()
      .describe("Priority 0-3 (default: 2)"),
    description: tool.schema.string().optional().describe("Bead description"),
    parent_id: tool.schema
      .string()
      .optional()
      .describe("Parent bead ID for epic children"),
  },
  execute: (args, ctx) => execTool("hive_create", args, ctx),
});

const hive_create_epic = tool({
  description: "Create epic with subtasks in one atomic operation",
  args: {
    epic_title: tool.schema.string().describe("Epic title"),
    epic_description: tool.schema
      .string()
      .optional()
      .describe("Epic description"),
    subtasks: tool.schema
      .array(
        tool.schema.object({
          title: tool.schema.string(),
          priority: tool.schema.number().min(0).max(3).optional(),
          files: tool.schema.array(tool.schema.string()).optional(),
        }),
      )
      .describe("Subtasks to create under the epic"),
  },
  execute: (args, ctx) => execTool("hive_create_epic", args, ctx),
});

const hive_query = tool({
  description: "Query beads with filters (replaces bd list, bd ready, bd wip)",
  args: {
    status: tool.schema
      .enum(["open", "in_progress", "blocked", "closed"])
      .optional()
      .describe("Filter by status"),
    type: tool.schema
      .enum(["bug", "feature", "task", "epic", "chore"])
      .optional()
      .describe("Filter by type"),
    ready: tool.schema
      .boolean()
      .optional()
      .describe("Only show unblocked beads"),
    limit: tool.schema
      .number()
      .optional()
      .describe("Max results (default: 20)"),
  },
  execute: (args, ctx) => execTool("hive_query", args, ctx),
});

const hive_update = tool({
  description: "Update bead status/description",
  args: {
    id: tool.schema.string().describe("Cell ID"),
    status: tool.schema
      .enum(["open", "in_progress", "blocked", "closed"])
      .optional()
      .describe("New status"),
    description: tool.schema.string().optional().describe("New description"),
    priority: tool.schema
      .number()
      .min(0)
      .max(3)
      .optional()
      .describe("New priority"),
  },
  execute: (args, ctx) => execTool("hive_update", args, ctx),
});

const hive_close = tool({
  description: "Close a bead with reason",
  args: {
    id: tool.schema.string().describe("Cell ID"),
    reason: tool.schema.string().describe("Completion reason"),
  },
  execute: (args, ctx) => execTool("hive_close", args, ctx),
});

const hive_start = tool({
  description: "Mark a bead as in-progress",
  args: {
    id: tool.schema.string().describe("Cell ID"),
  },
  execute: (args, ctx) => execTool("hive_start", args, ctx),
});

const hive_ready = tool({
  description: "Get the next ready bead (unblocked, highest priority)",
  args: {},
  execute: (args, ctx) => execTool("hive_ready", args, ctx),
});

const hive_sync = tool({
  description: "Sync beads to git and push (MANDATORY at session end)",
  args: {
    auto_pull: tool.schema.boolean().optional().describe("Pull before sync"),
  },
  execute: (args, ctx) => execTool("hive_sync", args, ctx),
});

const beads_link_thread = tool({
  description: "Add metadata linking bead to Agent Mail thread",
  args: {
    bead_id: tool.schema.string().describe("Cell ID"),
    thread_id: tool.schema.string().describe("Agent Mail thread ID"),
  },
  execute: (args, ctx) => execTool("beads_link_thread", args, ctx),
});

// =============================================================================
// Swarm Mail Tools (Embedded)
// =============================================================================

const swarmmail_init = tool({
  description: "Initialize Swarm Mail session (REQUIRED FIRST)",
  args: {
    project_path: tool.schema.string().describe("Absolute path to the project"),
    agent_name: tool.schema.string().optional().describe("Custom agent name"),
    task_description: tool.schema
      .string()
      .optional()
      .describe("Task description"),
  },
  execute: (args, ctx) => execTool("swarmmail_init", args, ctx),
});

const swarmmail_send = tool({
  description: "Send message to other agents via Swarm Mail",
  args: {
    to: tool.schema
      .array(tool.schema.string())
      .describe("Recipient agent names"),
    subject: tool.schema.string().describe("Message subject"),
    body: tool.schema.string().describe("Message body"),
    thread_id: tool.schema
      .string()
      .optional()
      .describe("Thread ID for grouping"),
    importance: tool.schema
      .enum(["low", "normal", "high", "urgent"])
      .optional()
      .describe("Message importance"),
    ack_required: tool.schema
      .boolean()
      .optional()
      .describe("Require acknowledgment"),
  },
  execute: (args, ctx) => execTool("swarmmail_send", args, ctx),
});

const swarmmail_inbox = tool({
  description: "Fetch inbox (CONTEXT-SAFE: bodies excluded, max 5 messages)",
  args: {
    limit: tool.schema
      .number()
      .max(5)
      .optional()
      .describe("Max messages (max 5)"),
    urgent_only: tool.schema
      .boolean()
      .optional()
      .describe("Only urgent messages"),
  },
  execute: (args, ctx) => execTool("swarmmail_inbox", args, ctx),
});

const swarmmail_read_message = tool({
  description: "Fetch ONE message body by ID",
  args: {
    message_id: tool.schema.number().describe("Message ID"),
  },
  execute: (args, ctx) => execTool("swarmmail_read_message", args, ctx),
});

const swarmmail_reserve = tool({
  description: "Reserve file paths for exclusive editing",
  args: {
    paths: tool.schema
      .array(tool.schema.string())
      .describe("File paths/patterns"),
    ttl_seconds: tool.schema.number().optional().describe("Reservation TTL"),
    exclusive: tool.schema.boolean().optional().describe("Exclusive lock"),
    reason: tool.schema.string().optional().describe("Reservation reason"),
  },
  execute: (args, ctx) => execTool("swarmmail_reserve", args, ctx),
});

const swarmmail_release = tool({
  description: "Release file reservations",
  args: {
    paths: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Paths to release"),
    reservation_ids: tool.schema
      .array(tool.schema.number())
      .optional()
      .describe("Reservation IDs"),
  },
  execute: (args, ctx) => execTool("swarmmail_release", args, ctx),
});

const swarmmail_ack = tool({
  description: "Acknowledge a message",
  args: {
    message_id: tool.schema.number().describe("Message ID"),
  },
  execute: (args, ctx) => execTool("swarmmail_ack", args, ctx),
});

const swarmmail_health = tool({
  description: "Check Swarm Mail database health",
  args: {},
  execute: (args, ctx) => execTool("swarmmail_health", args, ctx),
});

// =============================================================================
// Structured Tools
// =============================================================================

const structured_extract_json = tool({
  description: "Extract JSON from markdown/text response",
  args: {
    text: tool.schema.string().describe("Text containing JSON"),
  },
  execute: (args, ctx) => execTool("structured_extract_json", args, ctx),
});

const structured_validate = tool({
  description: "Validate agent response against a schema",
  args: {
    response: tool.schema.string().describe("Agent response to validate"),
    schema_name: tool.schema
      .enum(["evaluation", "task_decomposition", "cell_tree"])
      .describe("Schema to validate against"),
    max_retries: tool.schema
      .number()
      .min(1)
      .max(5)
      .optional()
      .describe("Max retries"),
  },
  execute: (args, ctx) => execTool("structured_validate", args, ctx),
});

const structured_parse_evaluation = tool({
  description: "Parse and validate evaluation response",
  args: {
    response: tool.schema.string().describe("Agent response"),
  },
  execute: (args, ctx) => execTool("structured_parse_evaluation", args, ctx),
});

const structured_parse_decomposition = tool({
  description: "Parse and validate task decomposition response",
  args: {
    response: tool.schema.string().describe("Agent response"),
  },
  execute: (args, ctx) => execTool("structured_parse_decomposition", args, ctx),
});

const structured_parse_cell_tree = tool({
  description: "Parse and validate bead tree response",
  args: {
    response: tool.schema.string().describe("Agent response"),
  },
  execute: (args, ctx) => execTool("structured_parse_cell_tree", args, ctx),
});

// =============================================================================
// Swarm Tools
// =============================================================================

const swarm_init = tool({
  description: "Initialize swarm session and check tool availability",
  args: {
    project_path: tool.schema.string().optional().describe("Project path"),
    isolation: tool.schema
      .enum(["worktree", "reservation"])
      .optional()
      .describe(
        "Isolation mode: 'worktree' for git worktree isolation, 'reservation' for file reservations (default)",
      ),
  },
  execute: (args, ctx) => execTool("swarm_init", args, ctx),
});

const swarm_select_strategy = tool({
  description: "Analyze task and recommend decomposition strategy",
  args: {
    task: tool.schema.string().min(1).describe("Task to analyze"),
    codebase_context: tool.schema
      .string()
      .optional()
      .describe("Codebase context"),
  },
  execute: (args, ctx) => execTool("swarm_select_strategy", args, ctx),
});

const swarm_plan_prompt = tool({
  description: "Generate strategy-specific decomposition prompt",
  args: {
    task: tool.schema.string().min(1).describe("Task to decompose"),
    strategy: tool.schema
      .enum(["file-based", "feature-based", "risk-based", "auto"])
      .optional()
      .describe("Decomposition strategy"),
    max_subtasks: tool.schema
      .number()
      .int()
      .min(2)
      .max(10)
      .optional()
      .describe("Max subtasks"),
    context: tool.schema.string().optional().describe("Additional context"),
    query_cass: tool.schema
      .boolean()
      .optional()
      .describe("Query CASS for similar tasks"),
    cass_limit: tool.schema
      .number()
      .int()
      .min(1)
      .max(10)
      .optional()
      .describe("CASS limit"),
  },
  execute: (args, ctx) => execTool("swarm_plan_prompt", args, ctx),
});

const swarm_decompose = tool({
  description: "Generate decomposition prompt for breaking task into subtasks",
  args: {
    task: tool.schema.string().min(1).describe("Task to decompose"),
    max_subtasks: tool.schema
      .number()
      .int()
      .min(2)
      .max(10)
      .optional()
      .describe("Max subtasks"),
    context: tool.schema.string().optional().describe("Additional context"),
    query_cass: tool.schema.boolean().optional().describe("Query CASS"),
    cass_limit: tool.schema
      .number()
      .int()
      .min(1)
      .max(10)
      .optional()
      .describe("CASS limit"),
  },
  execute: (args, ctx) => execTool("swarm_decompose", args, ctx),
});

const swarm_validate_decomposition = tool({
  description: "Validate a decomposition response against CellTreeSchema",
  args: {
    response: tool.schema.string().describe("Decomposition response"),
  },
  execute: (args, ctx) => execTool("swarm_validate_decomposition", args, ctx),
});

const swarm_status = tool({
  description: "Get status of a swarm by epic ID",
  args: {
    epic_id: tool.schema.string().describe("Epic bead ID"),
    project_key: tool.schema.string().describe("Project key"),
  },
  execute: (args, ctx) => execTool("swarm_status", args, ctx),
});

const swarm_progress = tool({
  description: "Report progress on a subtask to coordinator",
  args: {
    project_key: tool.schema.string().describe("Project key"),
    agent_name: tool.schema.string().describe("Agent name"),
    bead_id: tool.schema.string().describe("Cell ID"),
    status: tool.schema
      .enum(["in_progress", "blocked", "completed", "failed"])
      .describe("Status"),
    message: tool.schema.string().optional().describe("Progress message"),
    progress_percent: tool.schema
      .number()
      .min(0)
      .max(100)
      .optional()
      .describe("Progress %"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files modified"),
  },
  execute: (args, ctx) => execTool("swarm_progress", args, ctx),
});

const swarm_complete = tool({
  description:
    "Mark subtask complete with Verification Gate. Runs UBS scan, typecheck, and tests before allowing completion.",
  args: {
    project_key: tool.schema.string().describe("Project key"),
    agent_name: tool.schema.string().describe("Agent name"),
    bead_id: tool.schema.string().describe("Cell ID"),
    summary: tool.schema.string().describe("Completion summary"),
    evaluation: tool.schema.string().optional().describe("Self-evaluation JSON"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files modified - will be verified"),
    skip_ubs_scan: tool.schema.boolean().optional().describe("Skip UBS scan"),
    skip_verification: tool.schema
      .boolean()
      .optional()
      .describe("Skip ALL verification (UBS, typecheck, tests)"),
    skip_review: tool.schema
      .boolean()
      .optional()
      .describe("Skip review gate check"),
  },
  execute: (args, ctx) => execTool("swarm_complete", args, ctx),
});

const swarm_record_outcome = tool({
  description: "Record subtask outcome for implicit feedback scoring",
  args: {
    bead_id: tool.schema.string().describe("Cell ID"),
    duration_ms: tool.schema.number().int().min(0).describe("Duration in ms"),
    error_count: tool.schema
      .number()
      .int()
      .min(0)
      .optional()
      .describe("Error count"),
    retry_count: tool.schema
      .number()
      .int()
      .min(0)
      .optional()
      .describe("Retry count"),
    success: tool.schema.boolean().describe("Whether task succeeded"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files modified"),
    criteria: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Evaluation criteria"),
    strategy: tool.schema
      .enum(["file-based", "feature-based", "risk-based"])
      .optional()
      .describe("Strategy used"),
  },
  execute: (args, ctx) => execTool("swarm_record_outcome", args, ctx),
});

const swarm_subtask_prompt = tool({
  description: "Generate the prompt for a spawned subtask agent",
  args: {
    agent_name: tool.schema.string().describe("Agent name"),
    bead_id: tool.schema.string().describe("Cell ID"),
    epic_id: tool.schema.string().describe("Epic ID"),
    subtask_title: tool.schema.string().describe("Subtask title"),
    subtask_description: tool.schema
      .string()
      .optional()
      .describe("Description"),
    files: tool.schema.array(tool.schema.string()).describe("Files to work on"),
    shared_context: tool.schema.string().optional().describe("Shared context"),
  },
  execute: (args, ctx) => execTool("swarm_subtask_prompt", args, ctx),
});

const swarm_spawn_subtask = tool({
  description: "Prepare a subtask for spawning with Task tool",
  args: {
    bead_id: tool.schema.string().describe("Cell ID"),
    epic_id: tool.schema.string().describe("Epic ID"),
    subtask_title: tool.schema.string().describe("Subtask title"),
    subtask_description: tool.schema
      .string()
      .optional()
      .describe("Description"),
    files: tool.schema.array(tool.schema.string()).describe("Files to work on"),
    shared_context: tool.schema.string().optional().describe("Shared context"),
  },
  execute: (args, ctx) => execTool("swarm_spawn_subtask", args, ctx),
});

const swarm_complete_subtask = tool({
  description: "Handle subtask completion after Task agent returns",
  args: {
    bead_id: tool.schema.string().describe("Cell ID"),
    task_result: tool.schema.string().describe("Task result JSON"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files modified"),
  },
  execute: (args, ctx) => execTool("swarm_complete_subtask", args, ctx),
});

const swarm_evaluation_prompt = tool({
  description: "Generate self-evaluation prompt for a completed subtask",
  args: {
    bead_id: tool.schema.string().describe("Cell ID"),
    subtask_title: tool.schema.string().describe("Subtask title"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .describe("Files modified"),
  },
  execute: (args, ctx) => execTool("swarm_evaluation_prompt", args, ctx),
});

const swarm_broadcast = tool({
  description:
    "Broadcast context update to all agents working on the same epic",
  args: {
    project_path: tool.schema.string().describe("Project path"),
    agent_name: tool.schema.string().describe("Agent name"),
    epic_id: tool.schema.string().describe("Epic ID"),
    message: tool.schema.string().describe("Context update message"),
    importance: tool.schema
      .enum(["info", "warning", "blocker"])
      .optional()
      .describe("Priority level (default: info)"),
    files_affected: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files this context relates to"),
  },
  execute: (args, ctx) => execTool("swarm_broadcast", args, ctx),
});

// =============================================================================
// Worktree Isolation Tools
// =============================================================================

const swarm_worktree_create = tool({
  description:
    "Create a git worktree for isolated task execution. Worker operates in worktree, not main branch.",
  args: {
    project_path: tool.schema.string().describe("Absolute path to project root"),
    task_id: tool.schema.string().describe("Task/bead ID (e.g., bd-abc123.1)"),
    start_commit: tool.schema
      .string()
      .describe("Commit SHA to create worktree at (swarm start point)"),
  },
  execute: (args, ctx) => execTool("swarm_worktree_create", args, ctx),
});

const swarm_worktree_merge = tool({
  description:
    "Cherry-pick commits from worktree back to main branch. Call after worker completes.",
  args: {
    project_path: tool.schema.string().describe("Absolute path to project root"),
    task_id: tool.schema.string().describe("Task/bead ID"),
    start_commit: tool.schema
      .string()
      .optional()
      .describe("Original start commit (to find new commits)"),
  },
  execute: (args, ctx) => execTool("swarm_worktree_merge", args, ctx),
});

const swarm_worktree_cleanup = tool({
  description:
    "Remove a worktree after completion or abort. Idempotent - safe to call multiple times.",
  args: {
    project_path: tool.schema.string().describe("Absolute path to project root"),
    task_id: tool.schema.string().optional().describe("Task/bead ID to clean up"),
    cleanup_all: tool.schema
      .boolean()
      .optional()
      .describe("Remove all worktrees for this project"),
  },
  execute: (args, ctx) => execTool("swarm_worktree_cleanup", args, ctx),
});

const swarm_worktree_list = tool({
  description: "List all active worktrees for a project",
  args: {
    project_path: tool.schema.string().describe("Absolute path to project root"),
  },
  execute: (args, ctx) => execTool("swarm_worktree_list", args, ctx),
});

// =============================================================================
// Structured Review Tools
// =============================================================================

const swarm_review = tool({
  description:
    "Generate a review prompt for a completed subtask. Includes epic context, dependencies, and diff.",
  args: {
    project_key: tool.schema.string().describe("Project path"),
    epic_id: tool.schema.string().describe("Epic bead ID"),
    task_id: tool.schema.string().describe("Subtask bead ID to review"),
    files_touched: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Files modified (will get diff for these)"),
  },
  execute: (args, ctx) => execTool("swarm_review", args, ctx),
});

const swarm_review_feedback = tool({
  description:
    "Send review feedback to a worker. Tracks attempts (max 3). Fails task after 3 rejections.",
  args: {
    project_key: tool.schema.string().describe("Project path"),
    task_id: tool.schema.string().describe("Subtask bead ID"),
    worker_id: tool.schema.string().describe("Worker agent name"),
    status: tool.schema
      .enum(["approved", "needs_changes"])
      .describe("Review status"),
    summary: tool.schema.string().optional().describe("Review summary"),
    issues: tool.schema
      .string()
      .optional()
      .describe("JSON array of ReviewIssue objects (for needs_changes)"),
  },
  execute: (args, ctx) => execTool("swarm_review_feedback", args, ctx),
});

// =============================================================================
// Skills Tools
// =============================================================================

const skills_list = tool({
  description:
    "List all available skills from global, project, and bundled sources",
  args: {
    source: tool.schema
      .enum(["all", "global", "project", "bundled"])
      .optional()
      .describe("Filter by source (default: all)"),
  },
  execute: (args, ctx) => execTool("skills_list", args, ctx),
});

const skills_read = tool({
  description: "Read a skill's full content including SKILL.md and references",
  args: {
    name: tool.schema.string().describe("Skill name"),
  },
  execute: (args, ctx) => execTool("skills_read", args, ctx),
});

const skills_use = tool({
  description:
    "Get skill content formatted for injection into agent context. Use this when you need to apply a skill's knowledge to the current task.",
  args: {
    name: tool.schema.string().describe("Skill name"),
    context: tool.schema
      .string()
      .optional()
      .describe("Optional context about how the skill will be used"),
  },
  execute: (args, ctx) => execTool("skills_use", args, ctx),
});

const skills_create = tool({
  description: "Create a new skill with SKILL.md template",
  args: {
    name: tool.schema.string().describe("Skill name (kebab-case)"),
    description: tool.schema.string().describe("Brief skill description"),
    scope: tool.schema
      .enum(["global", "project"])
      .optional()
      .describe("Where to create (default: project)"),
    tags: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Skill tags for discovery"),
  },
  execute: (args, ctx) => execTool("skills_create", args, ctx),
});

const skills_update = tool({
  description: "Update an existing skill's SKILL.md content",
  args: {
    name: tool.schema.string().describe("Skill name"),
    content: tool.schema.string().describe("New SKILL.md content"),
  },
  execute: (args, ctx) => execTool("skills_update", args, ctx),
});

const skills_delete = tool({
  description: "Delete a skill (project skills only)",
  args: {
    name: tool.schema.string().describe("Skill name"),
  },
  execute: (args, ctx) => execTool("skills_delete", args, ctx),
});

const skills_init = tool({
  description: "Initialize skills directory in current project",
  args: {
    path: tool.schema
      .string()
      .optional()
      .describe("Custom path (default: .opencode/skills)"),
  },
  execute: (args, ctx) => execTool("skills_init", args, ctx),
});

const skills_add_script = tool({
  description: "Add an executable script to a skill",
  args: {
    skill_name: tool.schema.string().describe("Skill name"),
    script_name: tool.schema.string().describe("Script filename"),
    content: tool.schema.string().describe("Script content"),
    executable: tool.schema
      .boolean()
      .optional()
      .describe("Make executable (default: true)"),
  },
  execute: (args, ctx) => execTool("skills_add_script", args, ctx),
});

const skills_execute = tool({
  description: "Execute a skill's script",
  args: {
    skill_name: tool.schema.string().describe("Skill name"),
    script_name: tool.schema.string().describe("Script to execute"),
    args: tool.schema
      .array(tool.schema.string())
      .optional()
      .describe("Script arguments"),
  },
  execute: (args, ctx) => execTool("skills_execute", args, ctx),
});

// =============================================================================
// Plugin Export
// =============================================================================

// =============================================================================
// Compaction Hook - Swarm Recovery Context
// =============================================================================

/**
 * Detection result with confidence level
 */
interface SwarmDetection {
  detected: boolean;
  confidence: "high" | "medium" | "low" | "none";
  reasons: string[];
}

/**
 * Structured state snapshot for LLM-powered compaction
 * 
 * This is passed to the lite model to generate a continuation prompt
 * with concrete data instead of just instructions.
 */
interface SwarmStateSnapshot {
  sessionID: string;
  detection: {
    confidence: "high" | "medium" | "low" | "none";
    reasons: string[];
  };
  epic?: {
    id: string;
    title: string;
    status: string;
    subtasks: Array<{
      id: string;
      title: string;
      status: "open" | "in_progress" | "blocked" | "closed";
      files: string[];
      assignedTo?: string;
    }>;
  };
  messages: Array<{
    from: string;
    to: string[];
    subject: string;
    body: string;
    timestamp: number;
    importance?: string;
  }>;
  reservations: Array<{
    agent: string;
    paths: string[];
    exclusive: boolean;
    expiresAt: number;
  }>;
}

/**
 * Query actual swarm state using spawn (like detectSwarm does)
 * 
 * Returns structured snapshot of current state for LLM compaction.
 * Shells out to swarm CLI to get real data.
 */
async function querySwarmState(sessionID: string): Promise<SwarmStateSnapshot> {
  const startTime = Date.now();
  
  logCompaction("debug", "query_swarm_state_start", {
    session_id: sessionID,
    project_directory: projectDirectory,
  });

  try {
    // Query cells via swarm CLI
    const cliStart = Date.now();
    const cellsResult = await new Promise<{ exitCode: number; stdout: string; stderr: string }>(
      (resolve) => {
        const proc = spawn(SWARM_CLI, ["tool", "hive_query"], {
          cwd: projectDirectory,
          stdio: ["ignore", "pipe", "pipe"],
        });
        let stdout = "";
        let stderr = "";
        proc.stdout.on("data", (d) => {
          stdout += d;
        });
        proc.stderr.on("data", (d) => {
          stderr += d;
        });
        proc.on("close", (exitCode) =>
          resolve({ exitCode: exitCode ?? 1, stdout, stderr }),
        );
      },
    );
    const cliDuration = Date.now() - cliStart;

    logCompaction("debug", "query_swarm_state_cli_complete", {
      session_id: sessionID,
      duration_ms: cliDuration,
      exit_code: cellsResult.exitCode,
      stdout_length: cellsResult.stdout.length,
      stderr_length: cellsResult.stderr.length,
    });

    let cells: any[] = [];
    if (cellsResult.exitCode === 0) {
      try {
        cells = JSON.parse(cellsResult.stdout);
      } catch (parseErr) {
        logCompaction("error", "query_swarm_state_parse_failed", {
          session_id: sessionID,
          error: parseErr instanceof Error ? parseErr.message : String(parseErr),
          stdout_preview: cellsResult.stdout.substring(0, 500),
        });
      }
    }

    logCompaction("debug", "query_swarm_state_cells_parsed", {
      session_id: sessionID,
      cell_count: cells.length,
      cells: cells.map((c: any) => ({
        id: c.id,
        title: c.title,
        type: c.type,
        status: c.status,
        parent_id: c.parent_id,
      })),
    });

    // Find active epic (first unclosed epic with subtasks)
    const openEpics = cells.filter(
      (c: { type?: string; status: string }) =>
        c.type === "epic" && c.status !== "closed",
    );
    const epic = openEpics[0];

    logCompaction("debug", "query_swarm_state_epics", {
      session_id: sessionID,
      open_epic_count: openEpics.length,
      selected_epic: epic ? { id: epic.id, title: epic.title, status: epic.status } : null,
    });

    // Get subtasks if we have an epic
    const subtasks =
      epic && epic.id
        ? cells.filter(
            (c: { parent_id?: string }) => c.parent_id === epic.id,
          )
        : [];

    logCompaction("debug", "query_swarm_state_subtasks", {
      session_id: sessionID,
      subtask_count: subtasks.length,
      subtasks: subtasks.map((s: any) => ({
        id: s.id,
        title: s.title,
        status: s.status,
        files: s.files,
      })),
    });

    // TODO: Query swarm mail for messages and reservations
    // For MVP, use empty arrays - the fallback chain handles this
    const messages: SwarmStateSnapshot["messages"] = [];
    const reservations: SwarmStateSnapshot["reservations"] = [];

    // Run detection for confidence (already logged internally)
    const detection = await detectSwarm();

    const snapshot: SwarmStateSnapshot = {
      sessionID,
      detection: {
        confidence: detection.confidence,
        reasons: detection.reasons,
      },
      epic: epic
        ? {
            id: epic.id,
            title: epic.title,
            status: epic.status,
            subtasks: subtasks.map((s: {
              id: string;
              title: string;
              status: string;
              files?: string[];
            }) => ({
              id: s.id,
              title: s.title,
              status: s.status as "open" | "in_progress" | "blocked" | "closed",
              files: s.files || [],
            })),
          }
        : undefined,
      messages,
      reservations,
    };

    const totalDuration = Date.now() - startTime;
    logCompaction("debug", "query_swarm_state_complete", {
      session_id: sessionID,
      duration_ms: totalDuration,
      has_epic: !!snapshot.epic,
      epic_id: snapshot.epic?.id,
      subtask_count: snapshot.epic?.subtasks?.length ?? 0,
      message_count: snapshot.messages.length,
      reservation_count: snapshot.reservations.length,
    });

    return snapshot;
  } catch (err) {
    logCompaction("error", "query_swarm_state_exception", {
      session_id: sessionID,
      error: err instanceof Error ? err.message : String(err),
      stack: err instanceof Error ? err.stack : undefined,
      duration_ms: Date.now() - startTime,
    });

    // If query fails, return minimal snapshot
    const detection = await detectSwarm();
    return {
      sessionID,
      detection: {
        confidence: detection.confidence,
        reasons: detection.reasons,
      },
      messages: [],
      reservations: [],
    };
  }
}

/**
 * Generate compaction prompt using LLM
 * 
 * Shells out to `opencode run -m <liteModel>` with structured state.
 * Returns markdown continuation prompt or null on failure.
 * 
 * Timeout: 30 seconds
 */
async function generateCompactionPrompt(
  snapshot: SwarmStateSnapshot,
): Promise<string | null> {
  const startTime = Date.now();
  const liteModel = process.env.OPENCODE_LITE_MODEL || "claude-3-5-haiku-20241022";

  logCompaction("debug", "generate_compaction_prompt_start", {
    session_id: snapshot.sessionID,
    lite_model: liteModel,
    has_epic: !!snapshot.epic,
    epic_id: snapshot.epic?.id,
    subtask_count: snapshot.epic?.subtasks?.length ?? 0,
    snapshot_size: JSON.stringify(snapshot).length,
  });

  try {
    const promptText = `You are generating a continuation prompt for a compacted swarm coordination session.

Analyze this swarm state and generate a structured markdown prompt that will be given to the resumed session:

${JSON.stringify(snapshot, null, 2)}

Generate a prompt following this structure:

# üêù Swarm Continuation - [Epic Title or "Unknown"]

You are resuming coordination of an active swarm that was interrupted by context compaction.

## Epic State

**ID:** [epic ID or "Unknown"]
**Title:** [epic title or "No active epic"]
**Status:** [X/Y subtasks complete]
**Project:** ${projectDirectory}

## Subtask Status

### ‚úÖ Completed (N)
[List completed subtasks with IDs]

### üöß In Progress (N)
[List in-progress subtasks with IDs, files, agents if known]

### üö´ Blocked (N)
[List blocked subtasks]

### ‚è≥ Pending (N)
[List pending subtasks]

## Next Actions (IMMEDIATE)

[List 3-5 concrete actions with actual commands, using real IDs from the state]

## Coordinator Reminders

- **You are the coordinator** - Don't wait for instructions, orchestrate
- **Monitor actively** - Check messages every ~10 minutes
- **Unblock aggressively** - Resolve dependencies immediately
- **Review thoroughly** - 3-strike rule enforced
- **Ship it** - When all subtasks done, close the epic

Keep the prompt concise but actionable. Use actual data from the snapshot, not placeholders.`;

    logCompaction("debug", "generate_compaction_prompt_calling_llm", {
      session_id: snapshot.sessionID,
      prompt_length: promptText.length,
      model: liteModel,
      command: `opencode run -m ${liteModel} -- <prompt>`,
    });

    const llmStart = Date.now();
    const result = await new Promise<{ exitCode: number; stdout: string; stderr: string }>(
      (resolve, reject) => {
        const proc = spawn("opencode", ["run", "-m", liteModel, "--", promptText], {
          cwd: projectDirectory,
          stdio: ["ignore", "pipe", "pipe"],
          timeout: 30000, // 30 second timeout
        });

        let stdout = "";
        let stderr = "";

        proc.stdout.on("data", (d) => {
          stdout += d;
        });
        proc.stderr.on("data", (d) => {
          stderr += d;
        });

        proc.on("close", (exitCode) => {
          resolve({ exitCode: exitCode ?? 1, stdout, stderr });
        });

        proc.on("error", (err) => {
          reject(err);
        });

        // Timeout handling
        setTimeout(() => {
          proc.kill("SIGTERM");
          reject(new Error("LLM compaction timeout (30s)"));
        }, 30000);
      },
    );
    const llmDuration = Date.now() - llmStart;

    logCompaction("debug", "generate_compaction_prompt_llm_complete", {
      session_id: snapshot.sessionID,
      duration_ms: llmDuration,
      exit_code: result.exitCode,
      stdout_length: result.stdout.length,
      stderr_length: result.stderr.length,
      stderr_preview: result.stderr.substring(0, 500),
      stdout_preview: result.stdout.substring(0, 500),
    });

    if (result.exitCode !== 0) {
      logCompaction("error", "generate_compaction_prompt_llm_failed", {
        session_id: snapshot.sessionID,
        exit_code: result.exitCode,
        stderr: result.stderr,
        stdout: result.stdout,
        duration_ms: llmDuration,
      });
      return null;
    }

    // Extract the prompt from stdout (LLM may wrap in markdown)
    const prompt = result.stdout.trim();
    
    const totalDuration = Date.now() - startTime;
    logCompaction("debug", "generate_compaction_prompt_success", {
      session_id: snapshot.sessionID,
      total_duration_ms: totalDuration,
      llm_duration_ms: llmDuration,
      prompt_length: prompt.length,
      prompt_preview: prompt.substring(0, 500),
      prompt_has_content: prompt.length > 0,
    });

    return prompt.length > 0 ? prompt : null;
  } catch (err) {
    const totalDuration = Date.now() - startTime;
    logCompaction("error", "generate_compaction_prompt_exception", {
      session_id: snapshot.sessionID,
      error: err instanceof Error ? err.message : String(err),
      stack: err instanceof Error ? err.stack : undefined,
      duration_ms: totalDuration,
    });
    return null;
  }
}

/**
 * Check for swarm sign - evidence a swarm passed through
 *
 * Uses multiple signals with different confidence levels:
 * - HIGH: in_progress cells (active work)
 * - MEDIUM: Open subtasks, unclosed epics, recently updated cells
 * - LOW: Any cells exist
 *
 * Philosophy: Err on the side of continuation.
 * False positive = extra context (low cost)
 * False negative = lost swarm (high cost)
 */
async function detectSwarm(): Promise<SwarmDetection> {
  const startTime = Date.now();
  const reasons: string[] = [];
  let highConfidence = false;
  let mediumConfidence = false;
  let lowConfidence = false;

  logCompaction("debug", "detect_swarm_start", {
    project_directory: projectDirectory,
    cwd: process.cwd(),
  });

  try {
    const cliStart = Date.now();
    const result = await new Promise<{ exitCode: number; stdout: string; stderr: string }>(
      (resolve) => {
        // Use swarm tool to query beads
        const proc = spawn(SWARM_CLI, ["tool", "hive_query"], {
          cwd: projectDirectory,
          stdio: ["ignore", "pipe", "pipe"],
        });
        let stdout = "";
        let stderr = "";
        proc.stdout.on("data", (d) => {
          stdout += d;
        });
        proc.stderr.on("data", (d) => {
          stderr += d;
        });
        proc.on("close", (exitCode) =>
          resolve({ exitCode: exitCode ?? 1, stdout, stderr }),
        );
      },
    );
    const cliDuration = Date.now() - cliStart;

    logCompaction("debug", "detect_swarm_cli_complete", {
      duration_ms: cliDuration,
      exit_code: result.exitCode,
      stdout_length: result.stdout.length,
      stderr_length: result.stderr.length,
      stderr_preview: result.stderr.substring(0, 200),
    });

    if (result.exitCode !== 0) {
      logCompaction("warn", "detect_swarm_cli_failed", {
        exit_code: result.exitCode,
        stderr: result.stderr,
      });
      return { detected: false, confidence: "none", reasons: ["hive_query failed"] };
    }

    let cells: any[];
    try {
      cells = JSON.parse(result.stdout);
    } catch (parseErr) {
      logCompaction("error", "detect_swarm_parse_failed", {
        error: parseErr instanceof Error ? parseErr.message : String(parseErr),
        stdout_preview: result.stdout.substring(0, 500),
      });
      return { detected: false, confidence: "none", reasons: ["hive_query parse failed"] };
    }

    if (!Array.isArray(cells) || cells.length === 0) {
      logCompaction("debug", "detect_swarm_no_cells", {
        is_array: Array.isArray(cells),
        length: cells?.length ?? 0,
      });
      return { detected: false, confidence: "none", reasons: ["no cells found"] };
    }

    // Log ALL cells for debugging
    logCompaction("debug", "detect_swarm_cells_found", {
      total_cells: cells.length,
      cells: cells.map((c: any) => ({
        id: c.id,
        title: c.title,
        type: c.type,
        status: c.status,
        parent_id: c.parent_id,
        updated_at: c.updated_at,
        created_at: c.created_at,
      })),
    });

    // HIGH: Any in_progress cells
    const inProgress = cells.filter(
      (c: { status: string }) => c.status === "in_progress"
    );
    if (inProgress.length > 0) {
      highConfidence = true;
      reasons.push(`${inProgress.length} cells in_progress`);
      logCompaction("debug", "detect_swarm_in_progress", {
        count: inProgress.length,
        cells: inProgress.map((c: any) => ({ id: c.id, title: c.title })),
      });
    }

    // MEDIUM: Open subtasks (cells with parent_id)
    const subtasks = cells.filter(
      (c: { status: string; parent_id?: string }) =>
        c.status === "open" && c.parent_id
    );
    if (subtasks.length > 0) {
      mediumConfidence = true;
      reasons.push(`${subtasks.length} open subtasks`);
      logCompaction("debug", "detect_swarm_open_subtasks", {
        count: subtasks.length,
        cells: subtasks.map((c: any) => ({ id: c.id, title: c.title, parent_id: c.parent_id })),
      });
    }

    // MEDIUM: Unclosed epics
    const openEpics = cells.filter(
      (c: { status: string; type?: string }) =>
        c.type === "epic" && c.status !== "closed"
    );
    if (openEpics.length > 0) {
      mediumConfidence = true;
      reasons.push(`${openEpics.length} unclosed epics`);
      logCompaction("debug", "detect_swarm_open_epics", {
        count: openEpics.length,
        cells: openEpics.map((c: any) => ({ id: c.id, title: c.title, status: c.status })),
      });
    }

    // MEDIUM: Recently updated cells (last hour)
    const oneHourAgo = Date.now() - 60 * 60 * 1000;
    const recentCells = cells.filter(
      (c: { updated_at?: number }) => c.updated_at && c.updated_at > oneHourAgo
    );
    if (recentCells.length > 0) {
      mediumConfidence = true;
      reasons.push(`${recentCells.length} cells updated in last hour`);
      logCompaction("debug", "detect_swarm_recent_cells", {
        count: recentCells.length,
        one_hour_ago: oneHourAgo,
        cells: recentCells.map((c: any) => ({ 
          id: c.id, 
          title: c.title, 
          updated_at: c.updated_at,
          age_minutes: Math.round((Date.now() - c.updated_at) / 60000),
        })),
      });
    }

    // LOW: Any cells exist at all
    if (cells.length > 0) {
      lowConfidence = true;
      reasons.push(`${cells.length} total cells in hive`);
    }
  } catch (err) {
    // Detection failed, use fallback
    lowConfidence = true;
    reasons.push("Detection error, using fallback");
    logCompaction("error", "detect_swarm_exception", {
      error: err instanceof Error ? err.message : String(err),
      stack: err instanceof Error ? err.stack : undefined,
    });
  }

  // Determine overall confidence
  let confidence: "high" | "medium" | "low" | "none";
  if (highConfidence) {
    confidence = "high";
  } else if (mediumConfidence) {
    confidence = "medium";
  } else if (lowConfidence) {
    confidence = "low";
  } else {
    confidence = "none";
  }

  const totalDuration = Date.now() - startTime;
  logCompaction("debug", "detect_swarm_complete", {
    duration_ms: totalDuration,
    confidence,
    detected: confidence !== "none",
    reason_count: reasons.length,
    reasons,
    high_confidence: highConfidence,
    medium_confidence: mediumConfidence,
    low_confidence: lowConfidence,
  });

  return {
    detected: confidence !== "none",
    confidence,
    reasons,
  };
}

/**
 * Swarm-aware compaction context
 *
 * Injected during compaction to keep the swarm cooking. The coordinator should
 * wake up from compaction and immediately resume orchestration - spawning agents,
 * monitoring progress, unblocking work.
 */
const SWARM_COMPACTION_CONTEXT = `## üêù SWARM ACTIVE - Keep Cooking

You are the **COORDINATOR** of an active swarm. Context was compacted but the swarm is still running.

**YOUR JOB:** Keep orchestrating. Spawn agents. Monitor progress. Unblock work. Ship it.

### Preserve in Summary

Extract from session context:

1. **Epic & Subtasks** - IDs, titles, status, file assignments
2. **What's Running** - Which agents are active, what they're working on  
3. **What's Blocked** - Blockers and what's needed to unblock
4. **What's Done** - Completed work and any follow-ups needed
5. **What's Next** - Pending subtasks ready to spawn

### Summary Format

\`\`\`
## üêù Swarm State

**Epic:** <bd-xxx> - <title>
**Project:** <path>
**Progress:** X/Y subtasks complete

**Active:**
- <bd-xxx>: <title> [in_progress] ‚Üí <agent> working on <files>

**Blocked:**
- <bd-xxx>: <title> - BLOCKED: <reason>

**Completed:**
- <bd-xxx>: <title> ‚úì

**Ready to Spawn:**
- <bd-xxx>: <title> (files: <...>)
\`\`\`

### On Resume - IMMEDIATELY

1. \`swarm_status(epic_id="<epic>", project_key="<path>")\` - Get current state
2. \`swarmmail_inbox(limit=5)\` - Check for agent messages
3. \`swarm_review(project_key, epic_id, task_id, files_touched)\` - Review any completed work
4. \`swarm_review_feedback(project_key, task_id, worker_id, status, issues)\` - Approve or request changes
5. **Spawn ready subtasks** - Don't wait, fire them off
6. **Unblock blocked work** - Resolve dependencies, reassign if needed
7. **Collect completed work** - Close done subtasks, verify quality

### Keep the Swarm Cooking

- **Spawn aggressively** - If a subtask is ready and unblocked, spawn an agent
- **Monitor actively** - Check status, read messages, respond to blockers
- **Close the loop** - When all subtasks done, verify and close the epic
- **Don't stop** - The swarm runs until the epic is closed

**You are not waiting for instructions. You are the coordinator. Coordinate.**
`;

/**
 * Fallback detection prompt - tells the compactor what to look for
 * 
 * Used when we can't definitively detect a swarm but want to be safe.
 * The compactor can check the conversation context for these patterns.
 */
const SWARM_DETECTION_FALLBACK = `## üêù Swarm Detection - Check Your Context

**IMPORTANT:** Before summarizing, check if this session involves an active swarm.

Look for ANY of these patterns in the conversation:

### Tool Calls (definite swarm sign)
- \`swarm_decompose\`, \`swarm_spawn_subtask\`, \`swarm_status\`, \`swarm_complete\`
- \`swarmmail_init\`, \`swarmmail_reserve\`, \`swarmmail_send\`
- \`hive_create_epic\`, \`hive_start\`, \`hive_close\`

### IDs and Names
- Cell IDs: \`bd-xxx\`, \`bd-xxx.N\` (subtask format)
- Agent names: BlueLake, RedMountain, GreenValley, etc.
- Epic references: "epic", "subtask", "parent"

### Coordination Language
- "spawn", "worker", "coordinator"
- "reserve", "reservation", "files"
- "blocked", "unblock", "dependency"
- "progress", "complete", "in_progress"

### If You Find Swarm Evidence

Include this in your summary:
1. Epic ID and title
2. Project path
3. Subtask status (running/blocked/done/pending)
4. Any blockers or issues
5. What should happen next

**Then tell the resumed session:**
"This is an active swarm. Check swarm_status and swarmmail_inbox immediately."
`;

// Extended hooks type to include experimental compaction hook with new prompt API
type CompactionOutput = {
  context: string[];
  prompt?: string; // NEW API from OpenCode PR #5907
};

type ExtendedHooks = Hooks & {
  "experimental.session.compacting"?: (
    input: { sessionID: string },
    output: CompactionOutput,
  ) => Promise<void>;
};

export const SwarmPlugin: Plugin = async (
  input: PluginInput,
): Promise<ExtendedHooks> => {
  // CRITICAL: Set project directory from OpenCode input
  // Without this, CLI uses wrong database path
  projectDirectory = input.directory;
  
  return {
    tool: {
      // Beads
      hive_create,
      hive_create_epic,
      hive_query,
      hive_update,
      hive_close,
      hive_start,
      hive_ready,
      hive_sync,
      beads_link_thread,
      // Swarm Mail (Embedded)
      swarmmail_init,
      swarmmail_send,
      swarmmail_inbox,
      swarmmail_read_message,
      swarmmail_reserve,
      swarmmail_release,
      swarmmail_ack,
      swarmmail_health,
      // Structured
      structured_extract_json,
      structured_validate,
      structured_parse_evaluation,
      structured_parse_decomposition,
      structured_parse_cell_tree,
      // Swarm
      swarm_init,
      swarm_select_strategy,
      swarm_plan_prompt,
      swarm_decompose,
      swarm_validate_decomposition,
      swarm_status,
      swarm_progress,
      swarm_complete,
      swarm_record_outcome,
      swarm_subtask_prompt,
      swarm_spawn_subtask,
      swarm_complete_subtask,
      swarm_evaluation_prompt,
      swarm_broadcast,
      // Worktree Isolation
      swarm_worktree_create,
      swarm_worktree_merge,
      swarm_worktree_cleanup,
      swarm_worktree_list,
      // Structured Review
      swarm_review,
      swarm_review_feedback,
      // Skills
      skills_list,
      skills_read,
      skills_use,
      skills_create,
      skills_update,
      skills_delete,
      skills_init,
      skills_add_script,
      skills_execute,
    },

    // Swarm-aware compaction hook with LLM-powered continuation prompts
    // Three-level fallback chain: LLM ‚Üí static context ‚Üí detection fallback ‚Üí none
    "experimental.session.compacting": async (
      input: { sessionID: string },
      output: CompactionOutput,
    ) => {
      const startTime = Date.now();
      
      // =======================================================================
      // LOG: Compaction hook invoked - capture EVERYTHING we receive
      // =======================================================================
      logCompaction("info", "compaction_hook_invoked", {
        session_id: input.sessionID,
        project_directory: projectDirectory,
        input_keys: Object.keys(input),
        input_full: JSON.parse(JSON.stringify(input)), // Deep clone for logging
        output_keys: Object.keys(output),
        output_context_count: output.context?.length ?? 0,
        output_has_prompt_field: "prompt" in output,
        output_initial_state: {
          context: output.context,
          prompt: (output as any).prompt,
        },
        env: {
          OPENCODE_SESSION_ID: process.env.OPENCODE_SESSION_ID,
          OPENCODE_MESSAGE_ID: process.env.OPENCODE_MESSAGE_ID,
          OPENCODE_AGENT: process.env.OPENCODE_AGENT,
          OPENCODE_LITE_MODEL: process.env.OPENCODE_LITE_MODEL,
          SWARM_PROJECT_DIR: process.env.SWARM_PROJECT_DIR,
        },
        cwd: process.cwd(),
        timestamp: new Date().toISOString(),
      });

      // =======================================================================
      // STEP 1: Detect swarm state from hive
      // =======================================================================
      const detectionStart = Date.now();
      const detection = await detectSwarm();
      const detectionDuration = Date.now() - detectionStart;

      logCompaction("info", "swarm_detection_complete", {
        session_id: input.sessionID,
        duration_ms: detectionDuration,
        detected: detection.detected,
        confidence: detection.confidence,
        reasons: detection.reasons,
        reason_count: detection.reasons.length,
      });

      if (detection.confidence === "high" || detection.confidence === "medium") {
        // Definite or probable swarm - try LLM-powered compaction
        logCompaction("info", "swarm_detected_attempting_llm", {
          session_id: input.sessionID,
          confidence: detection.confidence,
          reasons: detection.reasons,
        });

        try {
          // Level 1: Query actual state
          const queryStart = Date.now();
          const snapshot = await querySwarmState(input.sessionID);
          const queryDuration = Date.now() - queryStart;

          logCompaction("info", "swarm_state_queried", {
            session_id: input.sessionID,
            duration_ms: queryDuration,
            has_epic: !!snapshot.epic,
            epic_id: snapshot.epic?.id,
            epic_title: snapshot.epic?.title,
            epic_status: snapshot.epic?.status,
            subtask_count: snapshot.epic?.subtasks?.length ?? 0,
            subtasks: snapshot.epic?.subtasks?.map(s => ({
              id: s.id,
              title: s.title,
              status: s.status,
              file_count: s.files?.length ?? 0,
            })),
            message_count: snapshot.messages?.length ?? 0,
            reservation_count: snapshot.reservations?.length ?? 0,
            detection_confidence: snapshot.detection.confidence,
            detection_reasons: snapshot.detection.reasons,
            full_snapshot: snapshot, // Log the entire snapshot
          });

          // Level 2: Generate prompt with LLM
          const llmStart = Date.now();
          const llmPrompt = await generateCompactionPrompt(snapshot);
          const llmDuration = Date.now() - llmStart;

          logCompaction("info", "llm_generation_complete", {
            session_id: input.sessionID,
            duration_ms: llmDuration,
            success: !!llmPrompt,
            prompt_length: llmPrompt?.length ?? 0,
            prompt_preview: llmPrompt?.substring(0, 500),
          });

          if (llmPrompt) {
            // SUCCESS: Use LLM-generated prompt
            const header = `[Swarm compaction: LLM-generated, ${detection.reasons.join(", ")}]\n\n`;
            const fullContent = header + llmPrompt;

            // Progressive enhancement: use new API if available
            if ("prompt" in output) {
              output.prompt = fullContent;
              logCompaction("info", "context_injected_via_prompt_api", {
                session_id: input.sessionID,
                content_length: fullContent.length,
                method: "output.prompt",
              });
            } else {
              output.context.push(fullContent);
              logCompaction("info", "context_injected_via_context_array", {
                session_id: input.sessionID,
                content_length: fullContent.length,
                method: "output.context.push",
                context_count_after: output.context.length,
              });
            }

            const totalDuration = Date.now() - startTime;
            logCompaction("info", "compaction_complete_llm_success", {
              session_id: input.sessionID,
              total_duration_ms: totalDuration,
              detection_duration_ms: detectionDuration,
              query_duration_ms: queryDuration,
              llm_duration_ms: llmDuration,
              confidence: detection.confidence,
              context_type: "llm_generated",
              content_length: fullContent.length,
            });
            return;
          }

          // LLM failed, fall through to static prompt
          logCompaction("warn", "llm_generation_returned_null", {
            session_id: input.sessionID,
            llm_duration_ms: llmDuration,
            falling_back_to: "static_prompt",
          });
        } catch (err) {
          // LLM failed, fall through to static prompt
          logCompaction("error", "llm_generation_failed", {
            session_id: input.sessionID,
            error: err instanceof Error ? err.message : String(err),
            error_stack: err instanceof Error ? err.stack : undefined,
            falling_back_to: "static_prompt",
          });
        }

        // Level 3: Fall back to static context
        const header = `[Swarm detected: ${detection.reasons.join(", ")}]\n\n`;
        const staticContent = header + SWARM_COMPACTION_CONTEXT;
        output.context.push(staticContent);

        const totalDuration = Date.now() - startTime;
        logCompaction("info", "compaction_complete_static_fallback", {
          session_id: input.sessionID,
          total_duration_ms: totalDuration,
          confidence: detection.confidence,
          context_type: "static_swarm_context",
          content_length: staticContent.length,
          context_count_after: output.context.length,
        });
      } else if (detection.confidence === "low") {
        // Level 4: Possible swarm - inject fallback detection prompt
        const header = `[Possible swarm: ${detection.reasons.join(", ")}]\n\n`;
        const fallbackContent = header + SWARM_DETECTION_FALLBACK;
        output.context.push(fallbackContent);

        const totalDuration = Date.now() - startTime;
        logCompaction("info", "compaction_complete_detection_fallback", {
          session_id: input.sessionID,
          total_duration_ms: totalDuration,
          confidence: detection.confidence,
          context_type: "detection_fallback",
          content_length: fallbackContent.length,
          context_count_after: output.context.length,
          reasons: detection.reasons,
        });
      } else {
        // Level 5: confidence === "none" - no injection, probably not a swarm
        const totalDuration = Date.now() - startTime;
        logCompaction("info", "compaction_complete_no_swarm", {
          session_id: input.sessionID,
          total_duration_ms: totalDuration,
          confidence: detection.confidence,
          context_type: "none",
          reasons: detection.reasons,
          context_count_unchanged: output.context.length,
        });
      }

      // =======================================================================
      // LOG: Final output state
      // =======================================================================
      logCompaction("debug", "compaction_hook_complete_final_state", {
        session_id: input.sessionID,
        output_context_count: output.context?.length ?? 0,
        output_context_lengths: output.context?.map(c => c.length) ?? [],
        output_has_prompt: !!(output as any).prompt,
        output_prompt_length: (output as any).prompt?.length ?? 0,
        total_duration_ms: Date.now() - startTime,
      });
    },
  };
};

export default SwarmPlugin;
